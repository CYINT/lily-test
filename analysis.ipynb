{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd022e9e71b990684bb084f6692ca9726ad306f2ea1f5baa58c815ba7aaff4219fd",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "22e9e71b990684bb084f6692ca9726ad306f2ea1f5baa58c815ba7aaff4219fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lily.Ai Technical Assessment\n",
    "\n",
    "The goal of this project is to provide a demonstration of technical skills for the position of Staff Data Scientist at Lily.AI. This notebook is part of a broader set of assets that can be found in the GitHub repository at https://github.com/CYINT/lily-test \n",
    "\n",
    "Instructions for the exercise, including a data dictionary for the raw data file, can be found in the accompanying Instructions.pdf file.\n",
    "\n",
    "The questions we are seeking to answer today are the following:\n",
    "\n",
    "1. What is Search to Product-View conversion rate?\n",
    "2. What is Product-View to Order-Complete conversion rate?\n",
    "3. Are there any interesting patterns from the analysis? \n",
    "\n",
    "## Problem approach.\n",
    "\n",
    "We will divide the problem into four steps.  \n",
    "1. Load the data into pandas and conduct data exploration.  \n",
    "2. Calculate the Search to Product-View conversion rate.  \n",
    "3. Calculate the Product-View to Order-Complete conversion rate.  \n",
    "4. Form hypotheses about patterns in the data and test those hypotheses using appropriate data science techniques.  \n",
    "\n",
    "## Step 1. Load the data and conduct an exploratory analysis.\n",
    "\n",
    "The data available is located in the `event_logs_v2.csv.gz` file. As this file is compressed using gzip, we will import the appropriate packages to unzip the file and load it into a pandas dataframe for exploratory analysis.\n",
    "\n",
    "As per the instructions, the following `event_code` values are mapped to the description:  \n",
    "1 - Search  \n",
    "2 - Product-View  \n",
    "3 - Order-Complete  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   event_code       event_timestamp                           user_id  \\\n",
       "0           2  2020-11-29T20:04:54Z  13fe7bed08c78ca6f563430b4fd284a1   \n",
       "1           2  2020-11-29T20:04:59Z  f081f5ce4e8bdd61d618bd64f0647e46   \n",
       "2           2  2020-11-29T19:58:19Z  d43f081630bd3a13518ea950213d7bcf   \n",
       "3           2  2020-11-29T19:58:34Z  5257b92203fd1122a1d9d09e0a236eb2   \n",
       "4           2  2020-11-29T19:58:44Z  0434613b9d24b9f475bde53472787825   \n",
       "\n",
       "                         product_id  \n",
       "0  cc5d78fc86ca1ea6dab7595d8b09a030  \n",
       "1  7b82f5b46759a9f238982f2a7c367ba1  \n",
       "2  bf91bb4cd7e62b353232e709a30f52be  \n",
       "3  a1317a5b5531f4dd2d1bbbf9f0ebecca  \n",
       "4  0b3ffd66553d9a2440b1ff8500b6b686  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_code</th>\n      <th>event_timestamp</th>\n      <th>user_id</th>\n      <th>product_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2020-11-29T20:04:54Z</td>\n      <td>13fe7bed08c78ca6f563430b4fd284a1</td>\n      <td>cc5d78fc86ca1ea6dab7595d8b09a030</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020-11-29T20:04:59Z</td>\n      <td>f081f5ce4e8bdd61d618bd64f0647e46</td>\n      <td>7b82f5b46759a9f238982f2a7c367ba1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-11-29T19:58:19Z</td>\n      <td>d43f081630bd3a13518ea950213d7bcf</td>\n      <td>bf91bb4cd7e62b353232e709a30f52be</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2020-11-29T19:58:34Z</td>\n      <td>5257b92203fd1122a1d9d09e0a236eb2</td>\n      <td>a1317a5b5531f4dd2d1bbbf9f0ebecca</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2020-11-29T19:58:44Z</td>\n      <td>0434613b9d24b9f475bde53472787825</td>\n      <td>0b3ffd66553d9a2440b1ff8500b6b686</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "#Define some constants for improving code readability later\n",
    "SEARCH = 1\n",
    "PRODUCT_VIEW = 2\n",
    "ORDER_COMPLETE = 3\n",
    "\n",
    "with gzip.open('./event_logs_v2.csv.gz', 'rb') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1265614 entries, 0 to 1265613\nData columns (total 4 columns):\n #   Column           Non-Null Count    Dtype \n---  ------           --------------    ----- \n 0   event_code       1265614 non-null  int64 \n 1   event_timestamp  1265614 non-null  object\n 2   user_id          1265614 non-null  object\n 3   product_id       1152471 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 38.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [
    "The data has been successfully loaded, based on the above output. We can see that there are 1,265,614 records. Let's do some data exploration to see if there is anything unusual that needs correcting in our dataset.\n",
    "\n",
    "Lets look at the event codes to ensure they are within the range of 1-3, and also convert the timestamp string into a datetime format in UTC timestamp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Event code range: 1-3\n",
      "Event timestamp range: 2020-11-10 00:00:01+00:00 - 2020-11-29 23:59:59+00:00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   event_code           event_timestamp                           user_id  \\\n",
       "0           2 2020-11-29 20:04:54+00:00  13fe7bed08c78ca6f563430b4fd284a1   \n",
       "1           2 2020-11-29 20:04:59+00:00  f081f5ce4e8bdd61d618bd64f0647e46   \n",
       "2           2 2020-11-29 19:58:19+00:00  d43f081630bd3a13518ea950213d7bcf   \n",
       "3           2 2020-11-29 19:58:34+00:00  5257b92203fd1122a1d9d09e0a236eb2   \n",
       "4           2 2020-11-29 19:58:44+00:00  0434613b9d24b9f475bde53472787825   \n",
       "\n",
       "                         product_id  \n",
       "0  cc5d78fc86ca1ea6dab7595d8b09a030  \n",
       "1  7b82f5b46759a9f238982f2a7c367ba1  \n",
       "2  bf91bb4cd7e62b353232e709a30f52be  \n",
       "3  a1317a5b5531f4dd2d1bbbf9f0ebecca  \n",
       "4  0b3ffd66553d9a2440b1ff8500b6b686  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_code</th>\n      <th>event_timestamp</th>\n      <th>user_id</th>\n      <th>product_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2020-11-29 20:04:54+00:00</td>\n      <td>13fe7bed08c78ca6f563430b4fd284a1</td>\n      <td>cc5d78fc86ca1ea6dab7595d8b09a030</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2020-11-29 20:04:59+00:00</td>\n      <td>f081f5ce4e8bdd61d618bd64f0647e46</td>\n      <td>7b82f5b46759a9f238982f2a7c367ba1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-11-29 19:58:19+00:00</td>\n      <td>d43f081630bd3a13518ea950213d7bcf</td>\n      <td>bf91bb4cd7e62b353232e709a30f52be</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2020-11-29 19:58:34+00:00</td>\n      <td>5257b92203fd1122a1d9d09e0a236eb2</td>\n      <td>a1317a5b5531f4dd2d1bbbf9f0ebecca</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2020-11-29 19:58:44+00:00</td>\n      <td>0434613b9d24b9f475bde53472787825</td>\n      <td>0b3ffd66553d9a2440b1ff8500b6b686</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print('Event code range: ' + str(data['event_code'].min()) + '-' + str(data['event_code'].max()))\n",
    "\n",
    "data_cleaned = data.copy()\n",
    "data_cleaned['event_timestamp'] = pd.to_datetime(data['event_timestamp'], utc=True)\n",
    "\n",
    "print('Event timestamp range: ' + str(data_cleaned['event_timestamp'].min()) + ' - ' + str(data_cleaned['event_timestamp'].max()))\n",
    "data_cleaned.head()"
   ]
  },
  {
   "source": [
    "Nothing strange in those two columns. Let's inspect the fact that there are null values in the product_id column. These values should only be from searches as we would not have identified a product at this stage of the funnel. We can test this assumption by looking at the range of `event_code` for product_ids that are null."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "null_product_ids = data_cleaned[data_cleaned['product_id'].isnull()]\n",
    "null_product_ids['event_code'].value_counts()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    113143\n",
       "Name: event_code, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "source": [
    "It looks like all of the events with null product ids are searches, so we do not have enough evidence of any anomalous data and we should preserve these in the data set.\n",
    "\n",
    "Let's explore some more:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2    1108507\n",
       "1     113143\n",
       "3      43964\n",
       "Name: event_code, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data_cleaned['event_code'].value_counts()"
   ]
  },
  {
   "source": [
    "## Step 2. Calculating Search Conversions\n",
    "\n",
    "There is a significant amount of data missing from the dataset that would normally be used to track conversions. In this case, we have no way of tying user actions to sessions except temporally. We also cannot tell if a user has taken any other action in between, such as revisiting the home page or changing categories from the menu.  \n",
    "\n",
    "We will define a conversion as a Product-View that is immediately preceded by a Search from the same user when sorting the data frame by time. In the real world, we might consider a certain threshold of time before a product-view is made, such as over a single day, but for this exercise it should suffice."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "57713"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data_cleaned_usercats = data_cleaned.copy()\n",
    "data_cleaned_usercats['user_id'] = data_cleaned['user_id'].astype('category').cat.codes\n",
    "sorted_data_conversions = data_cleaned_usercats[data_cleaned['event_code'].isin([SEARCH, PRODUCT_VIEW])].sort_values(['user_id', 'event_timestamp']).drop(['event_timestamp'], axis='columns')\n",
    "\n",
    "sorted_data_conversions['user_diff'] = sorted_data_conversions['user_id'].diff()\n",
    "sorted_data_conversions['event_diff'] = sorted_data_conversions['event_code'].diff()\n",
    "\n",
    "sorted_data_conversions['search_conversion'] = sorted_data_conversions.apply(lambda x: 1 if x['user_diff'] == 0 and x['event_diff'] == 1 else 0, axis=1)\n",
    "search_conversions = sorted_data_conversions['search_conversion'].sum()\n",
    "viewed_products_from_search = sorted_data_conversions.loc[sorted_data_conversions['search_conversion'] == 1]['product_id']\n",
    "search_conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5100890024128757"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "total_searches = data_cleaned[data_cleaned['event_code'] == SEARCH]['event_code'].count()\n",
    "search_conversion_rate = search_conversions / total_searches\n",
    "search_conversion_rate"
   ]
  },
  {
   "source": [
    "## 3. Product-View to Order-View conversions\n",
    "\n",
    "This is straightforward, as we will take the total number of Order-Complete and divide it by the total number of Product-Views. It doesn't matter if search preceded it. We won't filter out a Product-View if a user refreshed the page or if the user was buying multiple items in a single trip -- these might be considerations for a live site where we would track \"Add to cart\" data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.039660552436746"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "order_view_conversions = data_cleaned[data_cleaned['event_code'] == ORDER_COMPLETE]['event_code'].count() / data_cleaned[data_cleaned['event_code'] == PRODUCT_VIEW]['event_code'].count()\n",
    "order_view_conversions"
   ]
  },
  {
   "source": [
    "## 4. Hypothesis Testing - Are products found through search more likely to convert than those viewed outside of search?\n",
    "\n",
    "The null hypothesis is that conversion rates for products found through search does not differ from those of products viewed outside of search.  \n",
    "The alternate hypothesis is that conversion rates for products found through search differ from those of products viewed outside of search.\n",
    "\n",
    "We will setup the experiment by creating two groups.  \n",
    "Group A: Products found through search.\n",
    "Group B: Products found outside of search.\n",
    "\n",
    "We will conduct A/A and B/B tests on each group to look for evidence of confounding variables. If none are found, we will conduct A/B testing across both groups to determine if a statistically significant difference exists at 95% confidence.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 113079 entries, 2 to 1265601\nData columns (total 4 columns):\n #   Column           Non-Null Count   Dtype              \n---  ------           --------------   -----              \n 0   event_code       113079 non-null  int64              \n 1   event_timestamp  113079 non-null  datetime64[ns, UTC]\n 2   user_id          113079 non-null  object             \n 3   product_id       113079 non-null  object             \ndtypes: datetime64[ns, UTC](1), int64(1), object(2)\nmemory usage: 4.3+ MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1082 entries, 4023 to 1263531\nData columns (total 4 columns):\n #   Column           Non-Null Count  Dtype              \n---  ------           --------------  -----              \n 0   event_code       1082 non-null   int64              \n 1   event_timestamp  1082 non-null   datetime64[ns, UTC]\n 2   user_id          1082 non-null   object             \n 3   product_id       1082 non-null   object             \ndtypes: datetime64[ns, UTC](1), int64(1), object(2)\nmemory usage: 42.3+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.009568531734451135"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "group_a_views = data_cleaned[(data_cleaned['event_code'] == PRODUCT_VIEW) & (data_cleaned['product_id'].isin(viewed_products_from_search))]\n",
    "print(group_a_views.info())\n",
    "\n",
    "group_a_orders = data_cleaned[(data_cleaned['event_code'] == ORDER_COMPLETE) & (data_cleaned['product_id']).isin(group_a_views['product_id'])]\n",
    "group_a_orders.info()\n",
    "\n",
    "group_a_conversions = group_a_orders['event_code'].count() / group_a_views['event_code'].count()\n",
    "group_a_conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 995428 entries, 0 to 1265613\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype              \n",
      "---  ------           --------------   -----              \n",
      " 0   event_code       995428 non-null  int64              \n",
      " 1   event_timestamp  995428 non-null  datetime64[ns, UTC]\n",
      " 2   user_id          995428 non-null  object             \n",
      " 3   product_id       995428 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 38.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13710 entries, 10 to 1265372\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   event_code       13710 non-null  int64              \n",
      " 1   event_timestamp  13710 non-null  datetime64[ns, UTC]\n",
      " 2   user_id          13710 non-null  object             \n",
      " 3   product_id       13710 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(2)\n",
      "memory usage: 535.5+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0010869696251260765"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "group_b_views = data_cleaned[(data_cleaned['event_code'] == PRODUCT_VIEW) & (~data_cleaned['product_id'].isin(viewed_products_from_search))]\n",
    "print(group_b_views.info())\n",
    "\n",
    "group_b_orders = data_cleaned[(data_cleaned['event_code'] == ORDER_COMPLETE) & (data_cleaned['product_id']).isin(group_b_views['product_id'])]\n",
    "group_b_orders.info()\n",
    "\n",
    "group_b_conversions = group_a_orders['event_code'].count() / group_b_views['event_code'].count()\n",
    "group_b_conversions"
   ]
  },
  {
   "source": [
    "We have the two groups and the conversion rates. Now we need to do A/A and B/B testing. Let's also import statsmodels to help us."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'd:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n",
      "Requirement already satisfied: statsmodels in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: patsy>=0.5 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.15 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.21 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels) (1.2.3)\n",
      "Requirement already satisfied: scipy>=1.1 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels) (1.6.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: six in d:\\users\\dfredriksen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from patsy>=0.5->statsmodels) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7747460605882494"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "group_a1_views = group_a_views.sample(frac=0.5)\n",
    "group_a2_views = group_a_views[~group_a_views.index.isin(group_a1_views.index)]\n",
    "group_a1_orders = group_a_orders[group_a_orders['product_id'].isin(group_a1_views['product_id'])]\n",
    "group_a2_orders =  group_a_orders[group_a_orders['product_id'].isin(group_a2_views['product_id'])]\n",
    "\n",
    "group_a1_views_total = group_a1_views['product_id'].count()\n",
    "group_a1_orders_total = group_a1_orders['product_id'].count()\n",
    "group_a2_views_total = group_a2_views['product_id'].count()\n",
    "group_a2_orders_total = group_a2_orders['product_id'].count()\n",
    "\n",
    "stat, pval = proportions_ztest([group_a1_orders_total, group_a2_orders_total], [group_a1_views_total, group_a2_views_total])\n",
    "pval"
   ]
  },
  {
   "source": [
    "Our p-value is greater than our alpha (0.05) so we do not see any evidence of confounding variables in our A group.\n",
    "\n",
    "We repeat for the B group"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.32769725073191536"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "group_b1_views = group_b_views.sample(frac=0.5)\n",
    "group_b2_views = group_b_views[~group_b_views.index.isin(group_b1_views.index)]\n",
    "group_b1_orders = group_b_orders[group_b_orders['product_id'].isin(group_b1_views['product_id'])]\n",
    "group_b2_orders =  group_b_orders[group_b_orders['product_id'].isin(group_b2_views['product_id'])]\n",
    "\n",
    "group_b1_views_total = group_b1_views['product_id'].count()\n",
    "group_b1_orders_total = group_b1_orders['product_id'].count()\n",
    "group_b2_views_total = group_b2_views['product_id'].count()\n",
    "group_b2_orders_total = group_b2_orders['product_id'].count()\n",
    "\n",
    "stat, pval = proportions_ztest([group_b1_orders_total, group_b2_orders_total], [group_b1_views_total, group_b2_views_total])\n",
    "pval"
   ]
  },
  {
   "source": [
    "Our p-value is greater than our alpha (0.05) so we do not see any evidence of confounding variables in our B group.\n",
    "\n",
    "Now we can compare A and B to determine if finding a product through results have an impact on conversion rates."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.6834628719039872e-31"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "group_a_orders_total = group_a_orders['product_id'].count()\n",
    "group_b_orders_total = group_b_orders['product_id'].count()\n",
    "group_a_views_total = group_a_views['product_id'].count()\n",
    "group_b_views_total = group_b_views['product_id'].count()\n",
    "\n",
    "stat, pval = proportions_ztest([group_a_orders_total, group_b_orders_total], [group_a_views_total, group_b_views_total])\n",
    "pval"
   ]
  },
  {
   "source": [
    "Our P-value is less than our alpha of 0.05, which means that we can reject the null hypothesis with 95% confidence and assume that the alternate hypothesis is likely true -- finding a product through search has a different conversion rate than simply viewing a product without searching for it directly.\n",
    "\n",
    "We can also demonstrate the effect of the difference using Cohen's h formula\n",
    "\n",
    "$ h = \\phi_a - \\phi_b $  \n",
    "$ \\phi_i = 2 arcsine(\\sqrt{P_i}) $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.13000069343560056"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import numpy as np\n",
    "phi_a = 2*np.arcsin(np.sqrt(group_a_conversions))\n",
    "phi_b = 2*np.arcsin(np.sqrt(group_b_conversions))\n",
    "h = phi_a - phi_b\n",
    "h"
   ]
  },
  {
   "source": [
    "When Cohen's h is 0.1-0.3, the effect size is considered small. As a result, we can conclude that when users find their product through search first, there is a small increase in the likelihood of converting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}